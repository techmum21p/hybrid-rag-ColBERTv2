# Local RAG Chatbot with Image Understanding ğŸ¤–

A complete, production-ready RAG (Retrieval-Augmented Generation) chatbot that runs **100% locally** on your Mac Mini M4 with support for PDF documents containing images.

## âœ¨ Key Features

- âœ… **100% Local**: No cloud APIs, no external dependencies
- âœ… **Image Understanding**: Extracts and analyzes images from PDFs using LLaVA vision model
- âœ… **No RAGatouille**: Direct Jina ColBERT v2 implementation (no dependency conflicts!)
- âœ… **Hybrid Retrieval**: BM25s (lexical) + ColBERT (semantic) + RRF fusion + reranking
- âœ… **Markdown-Aware Chunking**: Respects document structure (headings, sections, tables)
- âœ… **Fast**: ~300ms retrieval, 2-4s total response time
- âœ… **SQLite Storage**: Simple, portable database

## ğŸ—ï¸ Architecture

```
PDF â†’ PyMuPDF4LLM â†’ Markdown
                       â†“
              Extract Images â†’ LLaVA Analysis
                       â†“           â†“
              Markdown-Aware â†’ Add Image
                 Chunking      Descriptions
                       â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
              â†“                 â†“
        BM25s Index      ColBERT Index
              â†“                 â†“
        Lexical Search   Semantic Search
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
              RRF Fusion (Top 50)
                       â†“
           ColBERT Reranking (Top 10)
                       â†“
              Ollama Generation
                       â†“
            Response + Citations
```

## ğŸ“¦ What's Included

### Files
- **local_rag_complete.py** - Complete implementation (1,400+ lines)
- **requirements.txt** - Python dependencies
- **README.md** - This file

### Key Components

1. **DocumentProcessor**
   - PDF â†’ Markdown conversion (PyMuPDF4LLM)
   - Image extraction and storage
   - Vision model analysis (LLaVA)
   - Chunk enrichment with image context

2. **MarkdownSemanticChunker**
   - Respects H1/H2/H3 hierarchy
   - Merges small sections
   - Splits large sections intelligently
   - Preserves tables, lists, code blocks

3. **JinaColBERTRetriever**
   - Direct ColBERT v2 implementation
   - Token-level embeddings
   - MaxSim scoring
   - No RAGatouille dependency

4. **HybridRetriever**
   - Stage 1: BM25s (top 100)
   - Stage 2: ColBERT (top 100)
   - Fusion: RRF (top 50)
   - Stage 3: ColBERT reranking (top 10)

5. **RAGChatbot**
   - Ollama integration
   - Conversation history
   - Context-aware responses
   - Source citations

## ğŸš€ Quick Start

### Prerequisites

**Hardware:**
- Mac Mini M4 (or any Mac with M-series chip)
- 16GB RAM minimum
- 10GB free disk space

**Software:**
- macOS 12+
- Python 3.10+
- Ollama

### Step 1: Install Ollama

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama server (keep this running in a terminal)
ollama serve
```

In a **new terminal**, pull the models:

```bash
# Text generation model (~3.5GB)
ollama pull llama3.2:3b

# Vision model for image analysis (~4.5GB)
ollama pull llava:7b
```

### Step 2: Set Up Python Environment

```bash
# Create virtual environment
python3.10 -m venv venv
source venv/bin/activate

# Upgrade pip
pip install --upgrade pip

# Install dependencies
pip install -r requirements.txt
```

### Step 3: Upload Your First PDF

```bash
python local_rag_complete.py --upload /path/to/document.pdf
```

**Example output:**
```
============================================================
Processing: technical_manual.pdf
============================================================

[Step 1/5] Converting PDF to Markdown... âœ“ 3.24s
  â€¢ Extracted 245,123 characters

[Step 2/5] Extracting and analyzing images...
    Analyzing image 1 on page 5... âœ“ (14.8s)
    Analyzing image 2 on page 8... âœ“ (15.2s)
    Analyzing image 3 on page 12... âœ“ (14.9s)
  âœ“ Completed in 45.18s
  â€¢ Extracted 3 images
  â€¢ Vision analysis: âœ“

[Step 3/5] Markdown-aware semantic chunking... âœ“ 0.23s
  â€¢ Created 287 semantic chunks

[Step 4/5] Enriching chunks with image context... âœ“ 0.12s
  â€¢ 15 chunks enriched with image context

[Step 5/5] Saving chunks to database... âœ“ 0.08s

[BM25s] Building lexical search index... âœ“ 0.54s
[ColBERT] Building semantic search index... âœ“ 12.87s

âœ… Document indexed successfully!
```

### Step 4: Start Chatting

```bash
python local_rag_complete.py --chat
```

**Example conversation:**

```
You: What does the architecture diagram show?

ğŸ” Retrieving relevant chunks...
   â€¢ BM25s: 0.032s
   â€¢ ColBERT: 0.189s
   â€¢ Fusion: 0.001s
   â€¢ Fetch: 0.004s
   â€¢ Rerank: 0.095s
   âœ“ Total retrieval: 0.321s

ğŸ¤– Generating response... âœ“ 1.9s
â±ï¸  Total: 2.2s